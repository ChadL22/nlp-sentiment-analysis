<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLP Sentiment Analysis Models</title>
    <link rel="stylesheet" href="css/styles.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script>
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true
            }
        });
    </script>
</head>
<body>
    <header>
        <div class="container">
            <h1>NLP Sentiment Analysis: Model Mechanics & Mathematics</h1>
            <p class="subtitle">A deep dive into how sentiment analysis models work under the hood</p>
            <nav>
                <ul>
                    <li><a href="#introduction">Introduction</a></li>
                    <li><a href="#models">Models</a></li>
                    <li><a href="#comparison">Comparison</a></li>
                    <li><a href="#resources">Resources</a></li>
                    <li><a href="#notebooks">Notebooks</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container">
        <section id="project-about">
            <div class="info-box">
                <h3>About This Project</h3>
                <p>This project started when a friend asked me to explain how sentiment analysis models work mathematically. Looking online, I couldn't find resources that clearly explained the mathematical foundations behind popular models like VADER and BERT/RoBERTa in an accessible way.</p>
                <p>Most tutorials I found focused on implementation or API usage, while academic papers often contained dense mathematics without clear connections to the actual code. There seemed to be a gap between practical guides and theoretical explanations.</p>
                <p>This repository is my attempt to bridge that gap by exploring both the practical applications and mathematical underpinnings of sentiment analysis models.</p>
                <p>This is very much a work in progress, and I'm learning along the way. I hope others who are curious about the mathematical underpinnings of these models might find this helpful in their own learning journey.</p>
            </div>
        </section>
        
        <section id="introduction">
            <h2>Introduction to Sentiment Analysis</h2>
            <p>Sentiment analysis is the computational process of determining the emotional tone behind text, providing insights into attitudes, opinions, and emotions. Modern approaches to sentiment analysis vary widely in their methodology, complexity, and application focus.</p>
            <p>This project explores two fundamentally different approaches through a mathematical lens:</p>
        </section>

        <section id="models" class="model-comparison">
            <div class="model-section" id="vader">
                <h2>VADER: Valence Aware Dictionary and sEntiment Reasoner</h2>
                <p>A deterministic approach to sentiment analysis through a carefully crafted lexicon combined with linguistic rules that capture common expression patterns.</p>
                
                <h3>Mathematical Foundation</h3>
                <ul>
                    <li>Word-level polarity scoring via manually labeled lexicon</li>
                    <li>Rule-based intensifiers, negations, and contrastive conjunctions</li>
                    <li>Heuristic normalization functions for final sentiment scores</li>
                    <li>Statistical validation against human raters</li>
                </ul>
                
                <div class="button-group">
                    <a href="vader-overview.html" class="btn">Practical Overview</a>
                    <a href="vader.html" class="btn">Mathematical Analysis</a>
                </div>
            </div>

            <div class="model-section" id="roberta">
                <h2>RoBERTa: Robustly Optimized BERT Approach</h2>
                <p>A neural network approach utilizing self-attention mechanisms and transfer learning to capture complex linguistic patterns and contextual relationships.</p>
                
                <h3>Mathematical Foundation</h3>
                <ul>
                    <li>Multi-head self-attention matrices for contextual representation</li>
                    <li>Layer normalization and feed-forward transformations</li>
                    <li>Subword tokenization with learned embedding spaces</li>
                    <li>Classification head fine-tuning with cross-entropy loss</li>
                </ul>
                
                <div class="button-group">
                    <a href="roberta-overview.html" class="btn">Practical Overview</a>
                    <a href="roberta.html" class="btn">Mathematical Analysis</a>
                </div>
            </div>
        </section>

        <section id="comparison">
            <h2>Model Comparison</h2>
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Aspect</th>
                        <th>VADER</th>
                        <th>RoBERTa</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Approach</td>
                        <td>Rule-based, lexicon-driven</td>
                        <td>Transformer-based, data-driven</td>
                    </tr>
                    <tr>
                        <td>Context Handling</td>
                        <td>Heuristic rules (e.g., "but")</td>
                        <td>Self-attention captures long-range context</td>
                    </tr>
                    <tr>
                        <td>Training</td>
                        <td>No training required</td>
                        <td>Pre-training + task-specific fine-tuning</td>
                    </tr>
                    <tr>
                        <td>Slang/Emojis</td>
                        <td>Explicitly coded in lexicon</td>
                        <td>Learns from data (if present in training)</td>
                    </tr>
                    <tr>
                        <td>Interpretability</td>
                        <td>High (transparent rules)</td>
                        <td>Low (black-box model)</td>
                    </tr>
                    <tr>
                        <td>Mathematical Complexity</td>
                        <td>Low (weighted sums with rules)</td>
                        <td>High (self-attention, neural networks)</td>
                    </tr>
                    <tr>
                        <td>Computational Cost</td>
                        <td>Very low</td>
                        <td>High (requires GPU for efficiency)</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>When to Use Which Model</h3>
            <div class="use-cases">
                <div class="use-case">
                    <h4>Use VADER When:</h4>
                    <ul>
                        <li>Analyzing short social media texts</li>
                        <li>Computational resources are limited</li>
                        <li>Interpretability is important</li>
                        <li>Quick deployment without training is needed</li>
                    </ul>
                </div>
                <div class="use-case">
                    <h4>Use RoBERTa When:</h4>
                    <ul>
                        <li>Analyzing long-form text (reviews, essays)</li>
                        <li>Contextual nuances are critical</li>
                        <li>Labeled training data is available</li>
                        <li>Maximum accuracy is the priority</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="resources">
            <h2>Resources & Further Reading</h2>
            <ul class="resources-list">
                <li>
                    <h3>VADER</h3>
                    <ul>
                        <li><a href="https://github.com/cjhutto/vaderSentiment" target="_blank">VADER GitHub Repository</a></li>
                        <li><a href="https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewFile/8109/8122" target="_blank">VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text</a></li>
                    </ul>
                </li>
                <li>
                    <h3>RoBERTa</h3>
                    <ul>
                        <li><a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta" target="_blank">RoBERTa GitHub Repository</a></li>
                        <li><a href="https://arxiv.org/abs/1907.11692" target="_blank">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></li>
                    </ul>
                </li>
                <li>
                    <h3>General Sentiment Analysis</h3>
                    <ul>
                        <li><a href="https://huggingface.co/docs/transformers/tasks/sequence_classification" target="_blank">Hugging Face - Text Classification</a></li>
                        <li><a href="https://www.nltk.org/howto/sentiment.html" target="_blank">NLTK Sentiment Analysis</a></li>
                    </ul>
                </li>
            </ul>
        </section>

        <section id="notebooks">
            <h2>Interactive Notebooks</h2>
            <p>Jupyter notebooks with interactive demonstrations of these models are currently in development.</p>
            
            <div class="model-cards">
                <div class="model-card">
                    <h3>VADER Notebook</h3>
                    <p>Explore the lexicon and rule-based sentiment analysis with hands-on examples and visualization of the scoring process.</p>
                    <a href="notebooks/vader_sentiment_analysis.ipynb" class="btn" target="_blank">View Notebook</a>
                </div>
                <div class="model-card">
                    <h3>RoBERTa Notebook</h3>
                    <p>Implement transformer-based sentiment analysis and visualize attention patterns and embedding spaces.</p>
                    <a href="notebooks/roberta_sentiment_analysis.ipynb" class="btn" target="_blank">View Notebook</a>
                </div>
            </div>
            <p class="note">Note: These notebooks contain template code with TODOs. They serve as a starting point for exploring the mathematical foundations of each model.</p>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 NLP Sentiment Analysis Models. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>